{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>__MÉTODOS NUMÉRICOS__</center>\n",
    "## <center>__PROJETO DA UNIDADE 2__</center>\n",
    "## <center>__TEMA: PageRank com Decomposições em Auto valores e Auto vetores__</center>\n",
    "#### <center>__ALUNO: Arthur Mauricio Thomaz Soares__</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "1. INTRODUÇÃO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo usado no notebook de exemplo se baseia nos conceitos de SVD e Decomposição de Eigen, da disciplina de métodos numericos.\n",
    "A partir desses métodos de decomposição de matrizes, o autor busca aplica-lós buscando extrair as correlações de páginas da Wikipédia e os seus respectivos links, calculando a \"impotância\" de um artigo a partir da sua correlação com outros artigos. Para isso, é usada uma matriz de adjacencia que interliga o artigo com seus respectivos links.\n",
    "Estudando esse notebook e pesquisando sobre o assunto, é interessante ver a variedade de informações que podemos tirar de matrizes bem montadas e organizadas com os métodos de decomposição. Por exemplo, nesse [link]() é mostrado que podemos facilmente extrair a correlação de posts a partir de suas palavras apenas usando SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "2. DESCRIÇÃO DO PROBLEMA\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O problema apresentado no notebook é o \"PageRank\", que é básicamente a categorização de páginas web que é muito importante hoje em dia para empresas como o Google.\n",
    "Com o PageRank, podemos encontrar de forma mais fácil e rápida páginas relacionadas a um assunto que buscamos, e páginas mais relevantes ao assunto desejado em menos tempo.\n",
    "Para esse page rank, o programa acessa páginas da Wikipédia a partir de um arquivo com as informações dessas páginas já sumarizadas disponível na DBPédia.\n",
    "A partir de métodos que serão explicados nos próximos tópicos, conseguimos classificar páginas por sua \"importância\" (calculada a partir das ligações dessa página com outras)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "3. MÉTODOS APLICADOS À SOLUÇÃO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD\n",
    "A decomposição de valores singulares de uma matriz é uma maneira de diagonizar a sua matriz e esse método pode ser utilizado para **quaisquer** matrizes (sendo quadradas ou não).\n",
    "Formulá:\n",
    "\n",
    "- $M=U\\Sigma V^*$\n",
    "\n",
    "- U = Mátriz Unitária\n",
    "\n",
    "- $\\Sigma$ = matriz diagonal do tamanho de M com números reais não negativos.\n",
    "\n",
    "$V^*$ = Vatriz unitária transposta conjugada de V\n",
    "### Decomposição de Eigen\n",
    "A decomposição de Eigen usa uma transformação linear para extrair um **eigenvector** da matriz, que também pode ser chamado de “característica do vetor”. Essa característica é calculada usando uma escalar $\\lambda$, essa escalar é chamada **eigenvalue**.\n",
    "\n",
    "$T(v) = \\lambda v$\n",
    "\n",
    "- T = transformação linear\n",
    "- v = eigenvector de uma matriz A\n",
    "- $\\lambda$ = eigenvalue do vétor v\n",
    "\n",
    "\n",
    "### Power Method\n",
    "O Power Method é usado para encontrar um eigenvalue dominante e eigenvector para uma matriz n * n. Para isso, ele itera sobre um valor p para encontrar o $\\lambda_1$ mais proximo do eigenvalue definitivo.\n",
    "[Explicação do Power Method](https://www.youtube.com/watch?v=_PDyi5BVY-E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "4. IMPLEMENTAÇÃO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente, o autor mostra algumas formas de medirmos processos do sistema operacional com Python, para facilitar o debug do nosso notebook. Para isso usamos as libs:\n",
    "- tqdm\n",
    "- sleep\n",
    "- os\n",
    "Além dessas bibliotecas também usamos o velho amigo numpy, scipy e o bz2 que serve para descomprimir os arquivos do DBPedia."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para motivos de exemplificação, eu vou usar os arquivos de redirects e de links apenas da linguagem pt-BR, pois não consegui fazer o download dos arquivos completos da DBPédia."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "PATH = 'data/dbpedia/'\n",
    "filenames = [\"redirects_br.nt\", \"page_links_br.nt\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "import os, numpy as np, pickle\n",
    "from bz2 import BZ2File\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import tqdm.notebook as tqdm\n",
    "from scipy import sparse\n",
    "\n",
    "from urllib.request import urlopen"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fazemos o download de arquivos comprimidos do DBPedia, que contem os dados da Wikipedia normalizados para análise.\n",
    "Os arquivos são grandes e o servidor não é muito rápido, então o download demora bastante.\n",
    "Por isso vamos usar arquivos com os dados parciais."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "PATH = 'data/dbpedia/'\n",
    "URL_BASE = 'http://downloads.dbpedia.org/3.8/br/'\n",
    "filenames = [\"redirects_br.nt.bz2\", \"page_links_br.nt.bz2\"]\n",
    "\n",
    "for filename in filenames:\n",
    "    if not os.path.exists(PATH+filename):\n",
    "        print(\"Downloading '%s', please wait...\" % filename)\n",
    "        open(PATH+filename, 'wb').write(urlopen(URL_BASE+filename).read())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Com os arquivos baixados, vamos criar uma matriz de adjacencia com as paginas e seus respectivos links.\n",
    "É importante salientar que as linhas do arquivo são do tipo:\n",
    "```\n",
    "<http://dbpedia.org/resource/AfghanistanHistory> <http://dbpedia.org/property/redirect>\n",
    "<http://dbpedia.org/resource/History_of_Afghanistan>\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "redirects_filename = PATH + filenames[0]\n",
    "page_links_filename = PATH + filenames[1]\n",
    "\n",
    "DBPEDIA_RESOURCE_PREFIX_LEN = len(\"http://br.dbpedia.org/resource/\")\n",
    "SLICE = slice(DBPEDIA_RESOURCE_PREFIX_LEN + 1, -1)\n",
    "\n",
    "# Removendo primeira e ultima linha por motivos de limpeza de dados\n",
    "def get_lines(filename): return (line.split() for line in BZ2File(filename))\n",
    "\n",
    "\n",
    "def get_redirect(targ, redirects):\n",
    "    seen = set()\n",
    "    while True:\n",
    "        transitive_targ = targ\n",
    "        targ = redirects.get(targ)\n",
    "        if targ is None or targ in seen: break\n",
    "        seen.add(targ)\n",
    "    return transitive_targ\n",
    "\n",
    "\n",
    "def get_redirects(redirects_filename):\n",
    "    redirects = {}\n",
    "    lines = get_lines(redirects_filename)\n",
    "    res = {}\n",
    "    #for src, _, targ, _ in tqdm.tqdm(lines):\n",
    "    for arr in tqdm.tqdm(lines):\n",
    "        key = arr[0][SLICE].decode(\"utf-8\")\n",
    "        res[key] = get_redirect(arr[2][SLICE].decode(\"utf-8\"), redirects)\n",
    "    return res\n",
    "\n",
    "\n",
    "redirects = get_redirects(redirects_filename)\n",
    "len(redirects)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42d35320e2564a849110870b2d38507a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "14675"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Com o dicionario criado, iremos criar um dicionario auxiliar para guardar o link e seu respectivo ID."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "def add_item(lst, redirects, index_map, item):\n",
    "    k = item[SLICE]\n",
    "    redirect_target = redirects.get(k)\n",
    "    res = True\n",
    "    if redirect_target is None:\n",
    "        res = False\n",
    "        redirect_target = k\n",
    "    update_index_map = index_map.setdefault(redirect_target, len(index_map))\n",
    "    lst.append(update_index_map)\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1015cbf82fdd42589bed162a591df90b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "1064862"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing the integer index map\n",
    "index_map = dict()  # links->IDs\n",
    "lines = get_lines(page_links_filename)\n",
    "source, destination, data = [], [], []\n",
    "for l, split in tqdm.tqdm(enumerate(lines)):\n",
    "    add_item(source, redirects, index_map, split[0].decode(\"utf-8\"))\n",
    "    add_item(destination, redirects, index_map, split[2].decode(\"utf-8\"))\n",
    "    data.append(1)\n",
    "\n",
    "len(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Temos 309K de items no nosso índice!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos fazer uns testes com nossos dados"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "index_map_aux = index_map.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "data": {
      "text/plain": "149579"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_map_aux['Harrison_Ford']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Os primeiros 10 artigos que citam Harrison Ford"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "data": {
      "text/plain": "[845530,\n 845531,\n 845532,\n 845533,\n 845534,\n 845535,\n 845536,\n 845537,\n 845538,\n 845539]"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i, x in enumerate(source) if x == 149579][:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Esses acima são as paginas que citam Harrison Ford.\n",
    "Vamos pegar um exemplo."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "data": {
      "text/plain": "(149579, 251127)"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source[845577], destination[845577]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden_Globe_Award_for_Best_Actor_-_Motion_Picture_Drama\n"
     ]
    }
   ],
   "source": [
    "for page_name, index in index_map.items():\n",
    "    if index == 251127:\n",
    "        print(page_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Indo no [link](https://en.wikipedia.org/wiki/Golden_Globe_Award_for_Best_Actor_%E2%80%93_Motion_Picture_Drama) da Wikipedia, podemos ver que realmente essa página cita o Harisson Ford."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "5. CASOS DE USO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "O caso de uso será utilizando o arquivo previamente carregado das páginas da Wikipedia traduzidas em PT-BR."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos criar uma matriz esparsa com os dados carregados e normalizados."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "n = len(data)\n",
    "X = sparse.coo_matrix((data, (destination, source)), shape=(n, n), dtype=np.float32)\n",
    "X = X.tocsr()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "também salvamos os nomes das páginas em um dicionario separado para facilitar a analise."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "names = {i: name for name, i in index_map.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para que não precisemos recalcular essa matriz esparsa, vamos salva-lá em um arquivo.\n",
    "(O autor faz isso porque ele trabalha com muitos dados, mas vamos fazer também por motivos de aprendizado)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "pickle.dump(X, open(PATH + 'X.pkl', 'wb'))\n",
    "pickle.dump(index_map, open(PATH + 'index_map.pkl', 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para carregar os arquivos basta executar o seguinte código:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "#X = pickle.load(open(PATH+'X.pkl', 'rb'))\n",
    "#index_map = pickle.load(open(PATH+'index_map.pkl', 'rb'))\n",
    "#names = {i: name for name, i in index_map.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Agora, iremos usar o Power Method para extrair os tópicos mais relevantes da nossa matriz:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "def show_ex(v):\n",
    "    print(', '.join(names[i] for i in np.abs(v.squeeze()).argsort()[-1:-10:-1]))\n",
    "\n",
    "\n",
    "def power_method(A, max_iter=100):\n",
    "    n = A.shape[1]\n",
    "    A_indices = A.indices\n",
    "    A_sum = A.sum(axis=0).A1\n",
    "    A.data /= np.take(A_sum, A_indices)\n",
    "\n",
    "    scores = np.ones(n, dtype=np.float32) * np.sqrt(A.sum() / (n * n))  # initial guess\n",
    "    for i in range(max_iter):\n",
    "        scores = A @ scores\n",
    "        nrm = np.linalg.norm(scores)\n",
    "        scores /= nrm\n",
    "\n",
    "    return scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "scores = power_method(X, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rummad:Prederourien, Bro-C'hall, Saozneg, Breizh, Brezhoneg, Europa_(kevandir), Galleg, Rummad:Bloavezhio\\u00F9, Yezh\n"
     ]
    }
   ],
   "source": [
    "show_ex(scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos tentar um resultado melhor com mais iterações:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rummad:Prederourien, Wikipedia:Kendivizo\\u00F9_reolata/Anvio\\u00F9_divoutin_gresianek_kozh_ha_modern, Degemer, Skoazell:FAG, Wikipedia:Politikerezh_stanka\\u00F1, Wikipedia:Pajenno\\u00F9_da_nulla\\u00F1, Wikipedia:Lammit_dreist_ar_reolenno\\u00F9, Patrom:Provi\\u00F1s_Vercelli, Wikipedia:Diello\\u00F9/Pajenno\\u00F9_da_nulla\\u00F1/rann_3_Ebrel_2006-Gwengolo_2006\n"
     ]
    }
   ],
   "source": [
    "scores = power_method(X)\n",
    "show_ex(scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}